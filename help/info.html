<!DOCTYPE html>
<html lang="en">

<head>
    <meta charset="utf-8" >
    <title>Documentation ReSync GUI</title>
    <link href="info_style.css" rel="stylesheet" >
    <link rel="preconnect" href="https://fonts.googleapis.com">
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin>
    <link href="https://fonts.googleapis.com/css2?family=Manrope:wght@200..800&display=swap" rel="stylesheet">
</head>

<body>
    <header>
        <div class="header">
            <img src="images/logo-resync.png" alt="Logo Home" class="logo-resync">
            <h1>Documentation ReSync GUI</h1>
        </div>
    </header>
    <main>
        <section>
            <h2 class="title-main-header">Open-source Python GUI for synchronizing intracranial data from DBS electrodes with external data</h2>
        </section>
        <div class="main-widget">
            <div class="main-text">
                <section id="general-information">
                    <h3>General Information</h3>
                    <p>
                        ReSync GUI is a Python Graphical User Interface (GUI) for synchronizing intracranial data from Deep Brain Stimulation 
                        (DBS) electrodes with external data. It is designed to be user-friendly and to facilitate the synchronization 
                        process. The GUI is built using the PyQt5 library and (should be) compatible with Windows, MacOS, and Linux operating 
                        systems. It is open-source and can be freely downloaded and modified by users.
                    </p>
                    <h4>Supported data formats:</h4> 
                    <p>
                        ReSync GUI synchronizes data from DBS electrodes ("intracranial data") with external data.<br>
                        The supported data formats are:
                        <ul>
                            <li>For the intracranial data: .mat<br>
                            The GUI is designed to be used on files preprocessed with the 
                            <a href="https://github.com/neuromodulation/perceive" target="_blank" class="clickable-link">perceive</a> toolbox.
                            This toolbox loads the .json file recovered from the clinician recording tablet after a recording session, 
                            and generates <a href="bids.neuroimaging.io/" target="_blank" class="clickable-link">BIDS-</a>inspired subject 
                            and session folders with the ieeg format specifier. All time series data are being exported as FieldTrip '.mat' files.
                            </li><br>
                            <li>For the external data: .xdf, .Poly5.
                                <ul>
                                    <li>The .Poly5 format is the output format of <a href="https://www.tmsi.com/" target="_blank" class="clickable-link">TMSi</a> data recorder</li>
                                    <li>The .xdf format is the output format of <a href="https://labstreaminglayer.org/#/" target="_blank" class="clickable-link">Lab Streaming Layer (LSL)</a></li>
                                </ul>
                                
                            </li>
                        </ul>
                    </p>
                    <h4>Supported saving formats after synchronization:</h4>
                    <p>
                        The synchronized data can be saved in the following formats:
                        <ul>
                            <li>If the input format was .Poly5:</li>
                            <ul>
                                <li>.mat</li>
                            </ul>
                            <li>If the input format was .xdf:</li>
                            <ul>
                                <li>.SET</li>
                                <li>.pkl</li>
                            </ul>
                        </ul>
                    </p>
                </section>
    
                <section id="installation">
                    <h3>Installation</h3>
                    <p>
                        <ol class="colored-numbers">
                            <li>
                                Clone the repository: <span class="code-text">git clone https://github.com/juliettevivien/Resync_GUI</span>
                            </li><br>
                            <li>
                                Navigate to the local version of ReSync-GUI and create the virtual environment
                            </li>
                            <ul>
                                <li>Manually, using anaconda prompt: follow the commands from Create virtual env.txt</li>
                                <li>Using pip: <span class="code-text">pip install -r requirements.txt </span></li>
                                <li>Using Conda: <span class="code-text">conda create --name <env_name> --file requirements.txt</span></li>
                            </ul><br>

                            <li>
                                Activate the virtual environment using the command: <span class="code-text">conda activate env_name</span></li>
                            </li><br>

                            <li>
                                Run the GUI using the command: <span class="code-text">python sync_gui_clean.py </span>
                            </li>
                        </ol>
                    </p>
                </section>
                
                <section id="usage">
                    <h3>Usage</h3>
                    <p>How to use the GUI.</p>
                    <p>
                        <ol class="colored-numbers">
                            <li>
                                Open the GUI by running the command: <span class="code-text">python sync_gui_clean.py</span>
                            </li><br>
                            <li>
                                Load the intracranial data by clicking on the "Load Intracranial Data" button.
                            </li><br>
                            <li>
                                Load the external data by clicking on the "Load External Data" button.
                            </li><br>
                            <li>
                                For each data type, select the channel containing the synchronization artifacts. 
                                See <a href="#sync-protocol" class="clickable-link">the synchronization protocol</a> 
                                for more information about how to create the artifacts during the recording. 
                                You can plot the channel to make sure you see the artifacts.
                            </li><br>
                            <li>
                                Detect the first artifact, either by using the automatic or the manual method.
                            </li><br>
                            <li>
                                Once the first artifact has been detected in both files, you can choose the fileformat 
                                in which you want to save the synchronized data (and a folder to save the results).
                            </li><br>
                            <li>
                                Optional: before saving, you can assess the "timeshift", i.e. you can plot the 
                                synchronized data together and verify if the last artifact is also aligned. 
                                Checking the timeshift is an important step to ensure that there was no data loss 
                                during the recording. If the timeshift is higher than 250ms, it might be a good 
                                idea to check for packet loss in the intracranial data. If the timeshift is 
                                smaller than 250ms, but still higher than 10ms, it might be a good idea to 
                                adjust the effective sampling frequency of the intracranial data.
                            </li>
                        </ol>
                    </p>
                </section>

                <section id="sync-protocol">
                    <h3>Synchronization Protocol</h3>
                    <p>
                        The synchronization protocol is a set of guidelines to help you create synchronization artifacts 
                        during the recording. These artifacts are used later on to synchronize the intracranial data with the external data thanks to this GUI.
                        <h4>Steps:</h4>
                        <ol class="colored-numbers">
                            <li>
                                <b>Prepare the recording:</b> Setup the BrainSense Streaming mode. Deactivate the ramp option of the stimulation on the clinician recording tablet. 
                                Keep the stimulation ON, but set it at 0mA bilaterally.
                            </li><br>
                            <li>
                                <b>Start the recording:</b> Start the recording of the intracranial data and the external data at the same time.
                            </li><br>
                            <li>
                                <b>Generate the artifacts:</b> In the clinician recording tablet, increase the stimulation amplitude to 1mA 
                                unilaterally in one step. 
                                This will generate a clear artifact in the intracranial data, which will be used for synchronization. 
                                Try to always perform the artifact on the same side.
                            </li><br>
                            <li>
                                <b>Perform your recording</b> After generating the artifact, decrease the stimulation amplitude to 0mA 
                                bilaterally if you are recording in DBS OFF, or slowly ramp up the stimulation back to the clinical 
                                settings if recording in DBS ON.
                            </li><br>
                            <li>
                                <b>Repeat the artifact at the end:</b> Repeat the stimulation pulses at the end, before stopping the streaming.
                                (Do not forget to put both hemispheres at 0mA before doing the pulses, and do the pulses ON THE SAME SIDE 
                                as the first artifact).
                            </li><br>
                            <li>
                                <b>Stop the recording:</b> Stop the recording of the intracranial data and the external data.
                            </li>
                    </p>
                </section>
            </div>

            <section id = "menu">
                <p class="menu-header">On this page</p>
                <ol class="colored-numbers">
                    <li><a href="#general-information">General Information</a></li>
                    <li><a href="#installation">Installation</a></li>
                    <li><a href="#usage">Usage</a></li>
                    <li><a href="#sync-protocol">Synchronization Protocol</a></li>
                </ol>
            </section>
        </div>
    </main>
    <footer>
        <div class="footer">
            <a target="_blank" href="https://x.com/vivien_juliette" class="lien-icone">
                <img src="images/logo-x-black.png" alt="Logo Twitter" class="logo-img">
            </a>
            <a target="_blank" href="https://www.linkedin.com/in/juliette-vivien-969ba7143/" class="lien-icone">
                <img src="images/logo-LinkedIn.png" alt="Logo Linkedin" class="logo-img">
            </a>
            <a target="_blank" href="https://github.com/juliettevivien" class="lien-icone">
                <img src="images/logo-github.png" alt="Logo Github" class="logo-img">
            </a>
            <a target="_blank" href="mailto:vivien.juliette@gmail.com" class="lien-icone">
                <img src="images/logo-mail.png" alt="Logo email" class="logo-img" title="vivien.juliette@gmail.com">
            </a>
        </div>
    </footer>
</body>